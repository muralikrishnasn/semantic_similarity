{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install fasttext if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://fasttext.cc/\n",
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/emilnuutinen/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the fasttext English pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the sts-benchmark data and remove lines that contain errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Remove \"warn_bad_lines=False\" to print the lines with errors.\n",
    "train_df = pd.read_csv('stsbenchmark/sts-train.csv', sep='\\t', engine='python', header=None, encoding='utf-8', error_bad_lines=False, warn_bad_lines=False)\n",
    "\n",
    "#data = []\n",
    "#with open('stsbenchmark/sts-train.csv') as f:\n",
    "#    for line in f.read().splitlines():\n",
    "#        splits = line.split('\\t')\n",
    "#        data.append({\n",
    "#            'score': float(splits[4]),\n",
    "#            's1': splits[5],\n",
    "#            's2': splits[6]\n",
    "#        }) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the genres, data shape and look at the head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "main-news        2976\nmain-captions    2000\nmain-forum        438\nName: 0, dtype: int64\n\n\nTrain dataset shape: (5414, 7)\n\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               0       1         2  3     4  \\\n0  main-captions  MSRvid  2012test  1  5.00   \n1  main-captions  MSRvid  2012test  4  3.80   \n2  main-captions  MSRvid  2012test  5  3.80   \n3  main-captions  MSRvid  2012test  6  2.60   \n4  main-captions  MSRvid  2012test  9  4.25   \n\n                                               5  \\\n0                         A plane is taking off.   \n1                A man is playing a large flute.   \n2  A man is spreading shreded cheese on a pizza.   \n3                   Three men are playing chess.   \n4                    A man is playing the cello.   \n\n                                                   6  \n0                        An air plane is taking off.  \n1                          A man is playing a flute.  \n2  A man is spreading shredded cheese on an uncoo...  \n3                         Two men are playing chess.  \n4                 A man seated is playing the cello.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>1</td>\n      <td>5.00</td>\n      <td>A plane is taking off.</td>\n      <td>An air plane is taking off.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>4</td>\n      <td>3.80</td>\n      <td>A man is playing a large flute.</td>\n      <td>A man is playing a flute.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>5</td>\n      <td>3.80</td>\n      <td>A man is spreading shreded cheese on a pizza.</td>\n      <td>A man is spreading shredded cheese on an uncoo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>6</td>\n      <td>2.60</td>\n      <td>Three men are playing chess.</td>\n      <td>Two men are playing chess.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>9</td>\n      <td>4.25</td>\n      <td>A man is playing the cello.</td>\n      <td>A man seated is playing the cello.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "print(train_df[0].value_counts())\n",
    "print('\\n')\n",
    "print('Train dataset shape: ' + str(train_df.shape))\n",
    "print('\\n')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two sentence paires that I will be comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0                  main-captions\n1                         MSRvid\n2                       2012test\n3                              1\n4                              5\n5         A plane is taking off.\n6    An air plane is taking off.\nName: 0, dtype: object\n\n\n0                     main-captions\n1                            MSRvid\n2                          2012test\n3                                68\n4                                 1\n5       A man is playing the piano.\n6    A woman is playing the violin.\nName: 45, dtype: object\n"
    }
   ],
   "source": [
    "print(train_df.loc[0])\n",
    "print('\\n')\n",
    "print(train_df.loc[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 = A plane is taking off.\ns2 = An air plane is taking off.\n\n\ns3 = A man is playing the piano.\ns4 = A woman is playing the violin.\n"
    }
   ],
   "source": [
    "s1 = train_df.loc[0][5]\n",
    "s2 = train_df.loc[0][6]\n",
    "s3 = train_df.loc[45][5]\n",
    "s4 = train_df.loc[45][6]\n",
    "\n",
    "print(f's1 = {s1}')\n",
    "print(f's2 = {s2}')\n",
    "print('\\n')\n",
    "print(f's3 = {s3}')\n",
    "print(f's4 = {s4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 vs s2 = 0.8981232047080994\ns3 vs s4 = 0.9621221423149109\ns1 vs s3 = 0.718084990978241\ns1 vs s4 = 0.7184442281723022\n"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "s1_vec = ft.get_sentence_vector(s1)\n",
    "s2_vec = ft.get_sentence_vector(s2)\n",
    "s3_vec = ft.get_sentence_vector(s3)\n",
    "s4_vec = ft.get_sentence_vector(s4)\n",
    "\n",
    "print(f's1 vs s2 = {1-distance.cosine(s1_vec,s2_vec)}')\n",
    "print(f's3 vs s4 = {1-distance.cosine(s3_vec,s4_vec)}')\n",
    "print(f's1 vs s3 = {1-distance.cosine(s1_vec,s3_vec)}')\n",
    "print(f's1 vs s4 = {1-distance.cosine(s1_vec,s4_vec)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 vs s2 = 0.8981070027806705\ns3 vs s4 = 0.9621134995201079\ns1 vs s3 = 0.6361684902231468\ns1 vs s4 = 0.7199339771232091\n"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr1, _ = pearsonr(s1_vec,s2_vec)\n",
    "corr2, _ = pearsonr(s3_vec,s4_vec)\n",
    "corr3, _ = pearsonr(s2_vec,s3_vec)\n",
    "corr4, _ = pearsonr(s1_vec,s4_vec)\n",
    "\n",
    "print(f's1 vs s2 = {corr1}')\n",
    "print(f's3 vs s4 = {corr2}')\n",
    "print(f's1 vs s3 = {corr3}')\n",
    "print(f's1 vs s4 = {corr4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the human scores and the fasttext scores and comparing them\n",
    "\n",
    "**https://ixa2.si.ehu.es/stswiki/index.php/STS_benchmark_reproducibility**\n",
    "\n",
    "> The averaged word embedding baselines compute a sentence embedding by averaging word embeddings and then using cosine to compute pairwise sentence similarity scores. \n",
    "\n",
    "> FastText: Since, to our knowledge, the tokenizer and preprocessing used for the pre-trained FastText embeddings is not publicly described. We use the following heuristics to preprocess and tokenize sentences for Fast-Text: numbers are converted into words, text is lowercased, and finally prefixed, suffixed and infixed punctuation is recursively removed from each token that does not match an entry in the model’s lexicon;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('stsbenchmark/sts-dev.csv') as f:\n",
    "    for line in f.read().splitlines():\n",
    "        splits = line.split('\\t')\n",
    "        data.append({\n",
    "            'score': float(splits[4]),\n",
    "            's1': splits[5],\n",
    "            's2': splits[6]\n",
    "        })\n",
    "\n",
    "# removes punctuation from sentences\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "# lowecase, tokenize and remove punctuation from sentences\n",
    "for x in data:\n",
    "    x['s1'].lower()\n",
    "    x['s2'].lower()\n",
    "    x['s1'] = tokenizer.tokenize(x['s1'])\n",
    "    x['s2'] = tokenizer.tokenize(x['s2'])\n",
    "    x['s1'] = ' '.join(x['s1'])\n",
    "    x['s2'] = ' '.join(x['s2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'score': 2.4,\n 's1': 'A woman is playing the guitar',\n 's2': 'A man is playing guitar'}"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_human = []\n",
    "\n",
    "for x in data:\n",
    "    score = x['score']/5\n",
    "    score_human.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_machine = []\n",
    "\n",
    "for x in data:\n",
    "    s1_vec = ft.get_sentence_vector(x['s1'])\n",
    "    s2_vec = ft.get_sentence_vector(x['s2'])\n",
    "    score = (1-distance.cosine(s1_vec,s2_vec))\n",
    "    score_machine.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "56.1\n"
    }
   ],
   "source": [
    "result, _ = pearsonr(score_machine, score_human)\n",
    "print(\"%.1f\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers and written numbers are expressed very differently in fasttext\n",
    "Converting numbers to written number probably produce much better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "40 and forty = 0.5712938904762268\n41 and forty-one = 0.465349406003952\n40 and 41 = 0.8811241388320923\nforty and forty-one = 0.81319260597229\n"
    }
   ],
   "source": [
    "vec_1 = ft.get_word_vector('40')\n",
    "vec_2 = ft.get_word_vector('forty')\n",
    "vec_3 = ft.get_word_vector('41')\n",
    "vec_4 = ft.get_word_vector('forty-one')\n",
    "print(f'40 and forty = {1-distance.cosine(vec_1,vec_2)}')\n",
    "print(f'41 and forty-one = {1-distance.cosine(vec_3,vec_4)}')\n",
    "print(f'40 and 41 = {1-distance.cosine(vec_1,vec_3)}')\n",
    "print(f'forty and forty-one = {1-distance.cosine(vec_2,vec_4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}