{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install fasttext if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://fasttext.cc/\n",
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/emilnuutinen/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the fasttext English pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the sts-benchmark data and remove lines that contain errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Remove \"warn_bad_lines=False\" to print the lines with errors.\n",
    "train_df = pd.read_csv('stsbenchmark/sts-train.csv', sep='\\t', engine='python', header=None, encoding='utf-8', error_bad_lines=False, warn_bad_lines=False)\n",
    "\n",
    "#data = []\n",
    "#with open('stsbenchmark/sts-train.csv') as f:\n",
    "#    for line in f.read().splitlines():\n",
    "#        splits = line.split('\\t')\n",
    "#        data.append({\n",
    "#            'score': float(splits[4]),\n",
    "#            's1': splits[5],\n",
    "#            's2': splits[6]\n",
    "#        }) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the genres, data shape and look at the head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "main-news        2976\nmain-captions    2000\nmain-forum        438\nName: 0, dtype: int64\n\n\nTrain dataset shape: (5414, 7)\n\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               0       1         2  3     4  \\\n0  main-captions  MSRvid  2012test  1  5.00   \n1  main-captions  MSRvid  2012test  4  3.80   \n2  main-captions  MSRvid  2012test  5  3.80   \n3  main-captions  MSRvid  2012test  6  2.60   \n4  main-captions  MSRvid  2012test  9  4.25   \n\n                                               5  \\\n0                         A plane is taking off.   \n1                A man is playing a large flute.   \n2  A man is spreading shreded cheese on a pizza.   \n3                   Three men are playing chess.   \n4                    A man is playing the cello.   \n\n                                                   6  \n0                        An air plane is taking off.  \n1                          A man is playing a flute.  \n2  A man is spreading shredded cheese on an uncoo...  \n3                         Two men are playing chess.  \n4                 A man seated is playing the cello.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>1</td>\n      <td>5.00</td>\n      <td>A plane is taking off.</td>\n      <td>An air plane is taking off.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>4</td>\n      <td>3.80</td>\n      <td>A man is playing a large flute.</td>\n      <td>A man is playing a flute.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>5</td>\n      <td>3.80</td>\n      <td>A man is spreading shreded cheese on a pizza.</td>\n      <td>A man is spreading shredded cheese on an uncoo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>6</td>\n      <td>2.60</td>\n      <td>Three men are playing chess.</td>\n      <td>Two men are playing chess.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>9</td>\n      <td>4.25</td>\n      <td>A man is playing the cello.</td>\n      <td>A man seated is playing the cello.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "print(train_df[0].value_counts())\n",
    "print('\\n')\n",
    "print('Train dataset shape: ' + str(train_df.shape))\n",
    "print('\\n')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two sentence paires that I will be comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0                  main-captions\n1                         MSRvid\n2                       2012test\n3                              1\n4                              5\n5         A plane is taking off.\n6    An air plane is taking off.\nName: 0, dtype: object\n\n\n0                     main-captions\n1                            MSRvid\n2                          2012test\n3                                68\n4                                 1\n5       A man is playing the piano.\n6    A woman is playing the violin.\nName: 45, dtype: object\n"
    }
   ],
   "source": [
    "print(train_df.loc[0])\n",
    "print('\\n')\n",
    "print(train_df.loc[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 = A plane is taking off.\ns2 = An air plane is taking off.\n\n\ns3 = A man is playing the piano.\ns4 = A woman is playing the violin.\n"
    }
   ],
   "source": [
    "s1 = train_df.loc[0][5]\n",
    "s2 = train_df.loc[0][6]\n",
    "s3 = train_df.loc[45][5]\n",
    "s4 = train_df.loc[45][6]\n",
    "\n",
    "print(f's1 = {s1}')\n",
    "print(f's2 = {s2}')\n",
    "print('\\n')\n",
    "print(f's3 = {s3}')\n",
    "print(f's4 = {s4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 vs s2 = 0.8981232047080994\ns3 vs s4 = 0.9621221423149109\ns1 vs s3 = 0.718084990978241\ns1 vs s4 = 0.7184442281723022\n"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "s1_vec = ft.get_sentence_vector(s1)\n",
    "s2_vec = ft.get_sentence_vector(s2)\n",
    "s3_vec = ft.get_sentence_vector(s3)\n",
    "s4_vec = ft.get_sentence_vector(s4)\n",
    "\n",
    "print(f's1 vs s2 = {1-distance.cosine(s1_vec,s2_vec)}')\n",
    "print(f's3 vs s4 = {1-distance.cosine(s3_vec,s4_vec)}')\n",
    "print(f's1 vs s3 = {1-distance.cosine(s1_vec,s3_vec)}')\n",
    "print(f's1 vs s4 = {1-distance.cosine(s1_vec,s4_vec)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 vs s2 = 0.8981070027806705\ns3 vs s4 = 0.9621134995201079\ns1 vs s3 = 0.6361684902231468\ns1 vs s4 = 0.7199339771232091\n"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr1, _ = pearsonr(s1_vec,s2_vec)\n",
    "corr2, _ = pearsonr(s3_vec,s4_vec)\n",
    "corr3, _ = pearsonr(s2_vec,s3_vec)\n",
    "corr4, _ = pearsonr(s1_vec,s4_vec)\n",
    "\n",
    "print(f's1 vs s2 = {corr1}')\n",
    "print(f's3 vs s4 = {corr2}')\n",
    "print(f's1 vs s3 = {corr3}')\n",
    "print(f's1 vs s4 = {corr4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the human scores and the fasttext scores and comparing them\n",
    "\n",
    "**https://ixa2.si.ehu.es/stswiki/index.php/STS_benchmark_reproducibility**\n",
    "\n",
    "> The averaged word embedding baselines compute a sentence embedding by averaging word embeddings and then using cosine to compute pairwise sentence similarity scores. \n",
    "\n",
    "> FastText: Since, to our knowledge, the tokenizer and preprocessing used for the pre-trained FastText embeddings is not publicly described. We use the following heuristics to preprocess and tokenize sentences for Fast-Text: numbers are converted into words, text is lowercased, and finally prefixed, suffixed and infixed punctuation is recursively removed from each token that does not match an entry in the modelâ€™s lexicon;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('stsbenchmark/sts-dev.csv') as f:\n",
    "    for line in f.read().splitlines():\n",
    "        splits = line.split('\\t')\n",
    "        data.append({\n",
    "            'score': float(splits[4]),\n",
    "            's1': splits[5],\n",
    "            's2': splits[6]\n",
    "        })\n",
    "\n",
    "# removes punctuation from sentences\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "# lowecase, tokenize and remove punctuation from sentences\n",
    "for x in data:\n",
    "    x['s1'].lower()\n",
    "    x['s2'].lower()\n",
    "    x['s1'] = tokenizer.tokenize(x['s1'])\n",
    "    x['s2'] = tokenizer.tokenize(x['s2'])\n",
    "    x['s1'] = ' '.join(x['s1'])\n",
    "    x['s2'] = ' '.join(x['s2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'score': 2.4,\n 's1': 'A woman is playing the guitar',\n 's2': 'A man is playing guitar'}"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_human = []\n",
    "\n",
    "for x in data:\n",
    "    score = x['score']/5\n",
    "    score_human.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_machine = []\n",
    "\n",
    "for x in data:\n",
    "    s1_vec = ft.get_sentence_vector(x['s1'])\n",
    "    s2_vec = ft.get_sentence_vector(x['s2'])\n",
    "    score = (1-distance.cosine(s1_vec,s2_vec))\n",
    "    score_machine.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "56.1\n"
    }
   ],
   "source": [
    "result, _ = pearsonr(score_machine, score_human)\n",
    "print(\"%.1f\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers and written numbers are expressed very differently in fasttext\n",
    "Converting numbers to written number probably produce much better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "40 and forty = 0.5712938904762268\n41 and forty-one = 0.465349406003952\n40 and 41 = 0.8811241388320923\nforty and forty-one = 0.81319260597229\n"
    }
   ],
   "source": [
    "vec_1 = ft.get_word_vector('40')\n",
    "vec_2 = ft.get_word_vector('forty')\n",
    "vec_3 = ft.get_word_vector('41')\n",
    "vec_4 = ft.get_word_vector('forty-one')\n",
    "print(f'40 and forty = {1-distance.cosine(vec_1,vec_2)}')\n",
    "print(f'41 and forty-one = {1-distance.cosine(vec_3,vec_4)}')\n",
    "print(f'40 and 41 = {1-distance.cosine(vec_1,vec_3)}')\n",
    "print(f'forty and forty-one = {1-distance.cosine(vec_2,vec_4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}