{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "* Convert numbers to words before tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing fastText for semantic similarity\n",
    "\n",
    "Install [fasttext](https://fasttext.cc/) if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/emilnuutinen/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get fastText ready to use\n",
    "\n",
    "We are using the normal English model.\n",
    "\n",
    "More info about the fastText [models](https://fasttext.cc/docs/en/crawl-vectors.html) for different languages.\n",
    "\n",
    "> We distribute pre-trained word vectors for 157 languages, trained on Common Crawl and Wikipedia using fastText. These models were trained using CBOW with position-weights, in dimension 300, with character n-grams of length 5, a window of size 5 and 10 negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "300"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "ft.get_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example about the word \"learning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(300,)\n[-3.1326819e-02  5.8432957e-03  3.5721278e-05  3.2791961e-02\n -9.6422508e-03 -5.0007503e-02  1.6288273e-02  3.5059921e-02\n -6.6784739e-02 -1.8172603e-03 -1.8895891e-02 -5.0050311e-02\n  5.2792020e-02  3.0742858e-02  1.2085622e-02 -1.8491376e-03\n  5.5508241e-02 -9.5799835e-03  3.2117605e-02  1.1655847e-02]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0.7456761598587036, 'learing'),\n (0.6895476579666138, 'Learning'),\n (0.6878188848495483, 'learning.This'),\n (0.6796225309371948, 'learning.The'),\n (0.6753033399581909, 'learning.It'),\n (0.6706692576408386, 'learning.So'),\n (0.6673312187194824, 'learning.What'),\n (0.6648250222206116, 'learning.But'),\n (0.664309024810791, 'learning-'),\n (0.6633586883544922, 'learning.As')]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "print(ft.get_word_vector('learning').shape)\n",
    "print(ft.get_word_vector('learning')[:20])\n",
    "\n",
    "ft.get_nearest_neighbors('learning') # may take some time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the sts-benchmark data and remove lines that contain errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove \"warn_bad_lines=False\" to print the lines that have errors.\n",
    "train_df = pd.read_csv('stsbenchmark/sts-train.csv', sep='\\t', engine='python', header=None, encoding='utf-8', error_bad_lines=False, warn_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A quick look at the dataset we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "main-news        2976\nmain-captions    2000\nmain-forum        438\nName: 0, dtype: int64\n\n\nTrain dataset shape: (5414, 7)\n\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               0       1         2  3     4  \\\n0  main-captions  MSRvid  2012test  1  5.00   \n1  main-captions  MSRvid  2012test  4  3.80   \n2  main-captions  MSRvid  2012test  5  3.80   \n3  main-captions  MSRvid  2012test  6  2.60   \n4  main-captions  MSRvid  2012test  9  4.25   \n\n                                               5  \\\n0                         A plane is taking off.   \n1                A man is playing a large flute.   \n2  A man is spreading shreded cheese on a pizza.   \n3                   Three men are playing chess.   \n4                    A man is playing the cello.   \n\n                                                   6  \n0                        An air plane is taking off.  \n1                          A man is playing a flute.  \n2  A man is spreading shredded cheese on an uncoo...  \n3                         Two men are playing chess.  \n4                 A man seated is playing the cello.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>1</td>\n      <td>5.00</td>\n      <td>A plane is taking off.</td>\n      <td>An air plane is taking off.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>4</td>\n      <td>3.80</td>\n      <td>A man is playing a large flute.</td>\n      <td>A man is playing a flute.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>5</td>\n      <td>3.80</td>\n      <td>A man is spreading shreded cheese on a pizza.</td>\n      <td>A man is spreading shredded cheese on an uncoo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>6</td>\n      <td>2.60</td>\n      <td>Three men are playing chess.</td>\n      <td>Two men are playing chess.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>9</td>\n      <td>4.25</td>\n      <td>A man is playing the cello.</td>\n      <td>A man seated is playing the cello.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "print(train_df[0].value_counts())\n",
    "print('\\n')\n",
    "print('Train dataset shape: ' + str(train_df.shape))\n",
    "print('\\n')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing two sentence paires with fastText as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0                  main-captions\n1                         MSRvid\n2                       2012test\n3                              1\n4                              5\n5         A plane is taking off.\n6    An air plane is taking off.\nName: 0, dtype: object\n\n\n0                     main-captions\n1                            MSRvid\n2                          2012test\n3                                68\n4                                 1\n5       A man is playing the piano.\n6    A woman is playing the violin.\nName: 45, dtype: object\n"
    }
   ],
   "source": [
    "print(train_df.loc[0])\n",
    "print('\\n')\n",
    "print(train_df.loc[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 = A plane is taking off.\ns2 = An air plane is taking off.\n\n\ns3 = A man is playing the piano.\ns4 = A woman is playing the violin.\n"
    }
   ],
   "source": [
    "s1 = train_df.loc[0][5]\n",
    "s2 = train_df.loc[0][6]\n",
    "s3 = train_df.loc[45][5]\n",
    "s4 = train_df.loc[45][6]\n",
    "\n",
    "print(f's1 = {s1}')\n",
    "print(f's2 = {s2}')\n",
    "print('\\n')\n",
    "print(f's3 = {s3}')\n",
    "print(f's4 = {s4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 vs s2 = 0.10187679529190063\nHuman score = 5.0\nfastText score = 4.5\ns3 vs s4 = 0.03787785768508911\nHuman score = 1.0\nfastText score = 4.8\ns1 vs s3 = 0.28191500902175903\ns1 vs s4 = 0.28155577182769775\n"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "s1_vec = ft.get_sentence_vector(s1)\n",
    "s2_vec = ft.get_sentence_vector(s2)\n",
    "s3_vec = ft.get_sentence_vector(s3)\n",
    "s4_vec = ft.get_sentence_vector(s4)\n",
    "\n",
    "print(f's1 vs s2 = {distance.cosine(s1_vec,s2_vec)}')\n",
    "print(f'Human score = {train_df.loc[0][4]}')\n",
    "print(f'fastText score = {round((1-distance.cosine(s1_vec,s2_vec))*5,1)}')\n",
    "\n",
    "print(f's3 vs s4 = {distance.cosine(s3_vec,s4_vec)}')\n",
    "print(f'Human score = {train_df.loc[45][4]}')\n",
    "print(f'fastText score = {round((1-distance.cosine(s3_vec,s4_vec))*5,1)}')\n",
    "\n",
    "print(f's1 vs s3 = {distance.cosine(s1_vec,s3_vec)}')\n",
    "print(f's1 vs s4 = {distance.cosine(s1_vec,s4_vec)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Getting the human scores and the fasttext scores and comparing them\n",
    "\n",
    "**https://ixa2.si.ehu.es/stswiki/index.php/STS_benchmark_reproducibility**\n",
    "\n",
    "> The averaged word embedding baselines compute a sentence embedding by averaging word embeddings and then using cosine to compute pairwise sentence similarity scores. \n",
    "\n",
    "> FastText: Since, to our knowledge, the tokenizer and preprocessing used for the pre-trained FastText embeddings is not publicly described. We use the following heuristics to preprocess and tokenize sentences for Fast-Text: numbers are converted into words, text is lowercased, and finally prefixed, suffixed and infixed punctuation is recursively removed from each token that does not match an entry in the model’s lexicon;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load the data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "data = []\n",
    "with open('stsbenchmark/sts-dev.csv') as f:\n",
    "    for line in f.read().splitlines():\n",
    "        splits = line.split('\\t')\n",
    "        data.append({\n",
    "            'score': float(splits[4]),\n",
    "            's1': splits[5],\n",
    "            's2': splits[6]\n",
    "        })\n",
    "\n",
    "# removes punctuation from sentences\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "# lowercase, tokenize and remove punctuation from sentences\n",
    "for x in data:\n",
    "    x['s1'].lower()\n",
    "    x['s2'].lower()\n",
    "    x['s1'] = tokenizer.tokenize(x['s1'])\n",
    "    x['s2'] = tokenizer.tokenize(x['s2'])\n",
    "    x['s1'] = ' '.join(x['s1'])\n",
    "    x['s2'] = ' '.join(x['s2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'score': 2.4,\n 's1': 'A woman is playing the guitar',\n 's2': 'A man is playing guitar'}"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Get the scores and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_human = []\n",
    "\n",
    "for x in data:\n",
    "    score = x['score']/5\n",
    "    score_human.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_machine = []\n",
    "\n",
    "for x in data:\n",
    "    s1_vec = ft.get_sentence_vector(x['s1'])\n",
    "    s2_vec = ft.get_sentence_vector(x['s2'])\n",
    "    score = (1-distance.cosine(s1_vec,s2_vec))\n",
    "    score_machine.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Compare human and fastText scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Pearsonr: 56.1\n"
    }
   ],
   "source": [
    "from scipy.spatial import pearsonr\n",
    "\n",
    "result, _ = pearsonr(score_machine, score_human)\n",
    "print('Pearsonr:', end=' ')\n",
    "print(\"%.1f\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Numbers and written numbers are expressed very differently in fasttext\n",
    "Converting numbers to written form could produce better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "40 and forty        =   0.4287061095237732\n41 and forty-one    =   0.534650593996048\n40 and 41           =   0.11887586116790771\nforty and forty-one =   0.18680739402770996\n"
    }
   ],
   "source": [
    "vec_1 = ft.get_word_vector('40')\n",
    "vec_2 = ft.get_word_vector('forty')\n",
    "vec_3 = ft.get_word_vector('41')\n",
    "vec_4 = ft.get_word_vector('forty-one')\n",
    "print(f'40 and forty        =   {distance.cosine(vec_1,vec_2)}')\n",
    "print(f'41 and forty-one    =   {distance.cosine(vec_3,vec_4)}')\n",
    "print(f'40 and 41           =   {distance.cosine(vec_1,vec_3)}')\n",
    "print(f'forty and forty-one =   {distance.cosine(vec_2,vec_4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'score': 1.0, 's1': 'Why is the speed of light 299 792 458 m s and not for instance 3 1 or 4 3 x 10 44 m s', 's2': 'Speed of light being finite is one of the fundamentals of our Universe'}\n"
    }
   ],
   "source": [
    "print(data[653])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install num2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from num2word import word\n",
    "\n",
    "def numbers_to_words(x):\n",
    "    y = []\n",
    "    for i in x:\n",
    "        if i.isdigit():\n",
    "            y.append(word(i))\n",
    "        else:\n",
    "            y.append(i)\n",
    "    return y\n",
    "\n",
    "for x in data:\n",
    "    x['s1'] = nltk.word_tokenize(x['s1'])\n",
    "    x['s1'] = numbers_to_words(x['s1'])\n",
    "    x['s1'] = ' '.join(x['s1'])\n",
    "    \n",
    "    x['s2'] = nltk.word_tokenize(x['s2'])\n",
    "    x['s2'] = numbers_to_words(x['s2'])\n",
    "    x['s2'] = ' '.join(x['s2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'score': 1.0, 's1': 'Why is the speed of light Two Hundred Ninety Nine Seven Hundred Ninety Two Four Hundred Fifty Eight m s and not for instance Three One or Four Three x Ten Fourty Four m s', 's2': 'Speed of light being finite is one of the fundamentals of our Universe'}\n"
    }
   ],
   "source": [
    "print(data[653])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_machine = []\n",
    "\n",
    "for x in data:\n",
    "    s1_vec = ft.get_sentence_vector(x['s1'])\n",
    "    s2_vec = ft.get_sentence_vector(x['s2'])\n",
    "    score = (1-distance.cosine(s1_vec,s2_vec))\n",
    "    score_machine.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "55.9\n"
    }
   ],
   "source": [
    "result, _ = pearsonr(score_machine, score_human)\n",
    "print(\"%.1f\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting numbers to words after tokenization creates wrong values as you can see from the example above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}