{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "* Convert numbers to words before tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing fastText for semantic similarity\n",
    "\n",
    "Install [fasttext](https://fasttext.cc/) if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/emilnuutinen/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get fastText ready to use\n",
    "\n",
    "We are using the normal English model.\n",
    "\n",
    "More info about the fastText [models](https://fasttext.cc/docs/en/crawl-vectors.html) for different languages.\n",
    "\n",
    "> We distribute pre-trained word vectors for 157 languages, trained on Common Crawl and Wikipedia using fastText. These models were trained using CBOW with position-weights, in dimension 300, with character n-grams of length 5, a window of size 5 and 10 negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "300"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "ft.get_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example about the word \"learning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(300,)\n[-3.1326819e-02  5.8432957e-03  3.5721278e-05  3.2791961e-02\n -9.6422508e-03 -5.0007503e-02  1.6288273e-02  3.5059921e-02\n -6.6784739e-02 -1.8172603e-03 -1.8895891e-02 -5.0050311e-02\n  5.2792020e-02  3.0742858e-02  1.2085622e-02 -1.8491376e-03\n  5.5508241e-02 -9.5799835e-03  3.2117605e-02  1.1655847e-02]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0.7456761598587036, 'learing'),\n (0.6895476579666138, 'Learning'),\n (0.6878188848495483, 'learning.This'),\n (0.6796225309371948, 'learning.The'),\n (0.6753033399581909, 'learning.It'),\n (0.6706692576408386, 'learning.So'),\n (0.6673312187194824, 'learning.What'),\n (0.6648250222206116, 'learning.But'),\n (0.664309024810791, 'learning-'),\n (0.6633586883544922, 'learning.As')]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "print(ft.get_word_vector('learning').shape)\n",
    "print(ft.get_word_vector('learning')[:20])\n",
    "\n",
    "ft.get_nearest_neighbors('learning') # may take some time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the sts-benchmark data and remove lines that contain errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove \"warn_bad_lines=False\" to print the lines that have errors.\n",
    "train_df = pd.read_csv('stsbenchmark/sts-train.csv', sep='\\t', engine='python', header=None, encoding='utf-8', error_bad_lines=False, warn_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A quick look at the dataset we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "main-news        2976\nmain-captions    2000\nmain-forum        438\nName: 0, dtype: int64\n\n\nTrain dataset shape: (5414, 7)\n\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               0       1         2  3     4  \\\n0  main-captions  MSRvid  2012test  1  5.00   \n1  main-captions  MSRvid  2012test  4  3.80   \n2  main-captions  MSRvid  2012test  5  3.80   \n3  main-captions  MSRvid  2012test  6  2.60   \n4  main-captions  MSRvid  2012test  9  4.25   \n\n                                               5  \\\n0                         A plane is taking off.   \n1                A man is playing a large flute.   \n2  A man is spreading shreded cheese on a pizza.   \n3                   Three men are playing chess.   \n4                    A man is playing the cello.   \n\n                                                   6  \n0                        An air plane is taking off.  \n1                          A man is playing a flute.  \n2  A man is spreading shredded cheese on an uncoo...  \n3                         Two men are playing chess.  \n4                 A man seated is playing the cello.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>1</td>\n      <td>5.00</td>\n      <td>A plane is taking off.</td>\n      <td>An air plane is taking off.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>4</td>\n      <td>3.80</td>\n      <td>A man is playing a large flute.</td>\n      <td>A man is playing a flute.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>5</td>\n      <td>3.80</td>\n      <td>A man is spreading shreded cheese on a pizza.</td>\n      <td>A man is spreading shredded cheese on an uncoo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>6</td>\n      <td>2.60</td>\n      <td>Three men are playing chess.</td>\n      <td>Two men are playing chess.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>main-captions</td>\n      <td>MSRvid</td>\n      <td>2012test</td>\n      <td>9</td>\n      <td>4.25</td>\n      <td>A man is playing the cello.</td>\n      <td>A man seated is playing the cello.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "print(train_df[0].value_counts())\n",
    "print('\\n')\n",
    "print('Train dataset shape: ' + str(train_df.shape))\n",
    "print('\\n')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing two sentence paires with fastText as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0                  main-captions\n1                         MSRvid\n2                       2012test\n3                              1\n4                              5\n5         A plane is taking off.\n6    An air plane is taking off.\nName: 0, dtype: object\n\n\n0                     main-captions\n1                            MSRvid\n2                          2012test\n3                                68\n4                                 1\n5       A man is playing the piano.\n6    A woman is playing the violin.\nName: 45, dtype: object\n"
    }
   ],
   "source": [
    "print(train_df.loc[0])\n",
    "print('\\n')\n",
    "print(train_df.loc[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 = A plane is taking off.\ns2 = An air plane is taking off.\n\n\ns3 = A man is playing the piano.\ns4 = A woman is playing the violin.\n"
    }
   ],
   "source": [
    "s1 = train_df.loc[0][5]\n",
    "s2 = train_df.loc[0][6]\n",
    "s3 = train_df.loc[45][5]\n",
    "s4 = train_df.loc[45][6]\n",
    "\n",
    "print(f's1 = {s1}')\n",
    "print(f's2 = {s2}')\n",
    "print('\\n')\n",
    "print(f's3 = {s3}')\n",
    "print(f's4 = {s4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "s1 vs s2 = 0.10187679529190063\nHuman score = 5.0\nfastText score = 4.5\ns3 vs s4 = 0.03787785768508911\nHuman score = 1.0\nfastText score = 4.8\ns1 vs s3 = 0.28191500902175903\ns1 vs s4 = 0.28155577182769775\n"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "s1_vec = ft.get_sentence_vector(s1)\n",
    "s2_vec = ft.get_sentence_vector(s2)\n",
    "s3_vec = ft.get_sentence_vector(s3)\n",
    "s4_vec = ft.get_sentence_vector(s4)\n",
    "\n",
    "print(f's1 vs s2 = {distance.cosine(s1_vec,s2_vec)}')\n",
    "print(f'Human score = {train_df.loc[0][4]}')\n",
    "print(f'fastText score = {round((1-distance.cosine(s1_vec,s2_vec))*5,1)}')\n",
    "\n",
    "print(f's3 vs s4 = {distance.cosine(s3_vec,s4_vec)}')\n",
    "print(f'Human score = {train_df.loc[45][4]}')\n",
    "print(f'fastText score = {round((1-distance.cosine(s3_vec,s4_vec))*5,1)}')\n",
    "\n",
    "print(f's1 vs s3 = {distance.cosine(s1_vec,s3_vec)}')\n",
    "print(f's1 vs s4 = {distance.cosine(s1_vec,s4_vec)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Getting the human scores and the fasttext scores and comparing them\n",
    "\n",
    "**https://ixa2.si.ehu.es/stswiki/index.php/STS_benchmark_reproducibility**\n",
    "\n",
    "> The averaged word embedding baselines compute a sentence embedding by averaging word embeddings and then using cosine to compute pairwise sentence similarity scores. \n",
    "\n",
    "> FastText: Since, to our knowledge, the tokenizer and preprocessing used for the pre-trained FastText embeddings is not publicly described. We use the following heuristics to preprocess and tokenize sentences for Fast-Text: numbers are converted into words, text is lowercased, and finally prefixed, suffixed and infixed punctuation is recursively removed from each token that does not match an entry in the modelâ€™s lexicon;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load the data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "data = []\n",
    "with open('stsbenchmark/sts-dev.csv') as f:\n",
    "    for line in f.read().splitlines():\n",
    "        splits = line.split('\\t')\n",
    "        data.append({\n",
    "            'score': float(splits[4]),\n",
    "            's1': splits[5],\n",
    "            's2': splits[6]\n",
    "        })\n",
    "\n",
    "# removes punctuation from sentences\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "# lowercase, tokenize and remove punctuation from sentences\n",
    "for x in data:\n",
    "    x['s1'].lower()\n",
    "    x['s2'].lower()\n",
    "    x['s1'] = tokenizer.tokenize(x['s1'])\n",
    "    x['s2'] = tokenizer.tokenize(x['s2'])\n",
    "    x['s1'] = ' '.join(x['s1'])\n",
    "    x['s2'] = ' '.join(x['s2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'score': 2.4,\n 's1': 'A woman is playing the guitar',\n 's2': 'A man is playing guitar'}"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Get the scores and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_human = []\n",
    "\n",
    "for x in data:\n",
    "    score = x['score']/5\n",
    "    score_human.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_machine = []\n",
    "\n",
    "for x in data:\n",
    "    s1_vec = ft.get_sentence_vector(x['s1'])\n",
    "    s2_vec = ft.get_sentence_vector(x['s2'])\n",
    "    score = (1-distance.cosine(s1_vec,s2_vec))\n",
    "    score_machine.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Compare human and fastText scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Pearsonr: 56.1\n"
    }
   ],
   "source": [
    "from scipy.spatial import pearsonr\n",
    "\n",
    "result, _ = pearsonr(score_machine, score_human)\n",
    "print('Pearsonr:', end=' ')\n",
    "print(\"%.1f\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Numbers and written numbers are expressed very differently in fasttext\n",
    "Converting numbers to written form could produce better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "40 and forty        =   0.4287061095237732\n41 and forty-one    =   0.534650593996048\n40 and 41           =   0.11887586116790771\nforty and forty-one =   0.18680739402770996\n"
    }
   ],
   "source": [
    "vec_1 = ft.get_word_vector('40')\n",
    "vec_2 = ft.get_word_vector('forty')\n",
    "vec_3 = ft.get_word_vector('41')\n",
    "vec_4 = ft.get_word_vector('forty-one')\n",
    "print(f'40 and forty        =   {distance.cosine(vec_1,vec_2)}')\n",
    "print(f'41 and forty-one    =   {distance.cosine(vec_3,vec_4)}')\n",
    "print(f'40 and 41           =   {distance.cosine(vec_1,vec_3)}')\n",
    "print(f'forty and forty-one =   {distance.cosine(vec_2,vec_4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'score': 1.0, 's1': 'Why is the speed of light 299 792 458 m s and not for instance 3 1 or 4 3 x 10 44 m s', 's2': 'Speed of light being finite is one of the fundamentals of our Universe'}\n"
    }
   ],
   "source": [
    "print(data[653])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install num2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from num2word import word\n",
    "\n",
    "def numbers_to_words(x):\n",
    "    y = []\n",
    "    for i in x:\n",
    "        if i.isdigit():\n",
    "            y.append(word(i))\n",
    "        else:\n",
    "            y.append(i)\n",
    "    return y\n",
    "\n",
    "for x in data:\n",
    "    x['s1'] = nltk.word_tokenize(x['s1'])\n",
    "    x['s1'] = numbers_to_words(x['s1'])\n",
    "    x['s1'] = ' '.join(x['s1'])\n",
    "    \n",
    "    x['s2'] = nltk.word_tokenize(x['s2'])\n",
    "    x['s2'] = numbers_to_words(x['s2'])\n",
    "    x['s2'] = ' '.join(x['s2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'score': 1.0, 's1': 'Why is the speed of light Two Hundred Ninety Nine Seven Hundred Ninety Two Four Hundred Fifty Eight m s and not for instance Three One or Four Three x Ten Fourty Four m s', 's2': 'Speed of light being finite is one of the fundamentals of our Universe'}\n"
    }
   ],
   "source": [
    "print(data[653])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_machine = []\n",
    "\n",
    "for x in data:\n",
    "    s1_vec = ft.get_sentence_vector(x['s1'])\n",
    "    s2_vec = ft.get_sentence_vector(x['s2'])\n",
    "    score = (1-distance.cosine(s1_vec,s2_vec))\n",
    "    score_machine.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "55.9\n"
    }
   ],
   "source": [
    "result, _ = pearsonr(score_machine, score_human)\n",
    "print(\"%.1f\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting numbers to words after tokenization creates wrong values as you can see from the example above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}