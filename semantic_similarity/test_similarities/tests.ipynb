{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASER\n",
    "!python -m laserembeddings download-models\n",
    "\n",
    "# SENTENCE-BERT\n",
    "!pip install transformers # https://github.com/huggingface/transformers\n",
    "!pip install -U sentence-transformers # https://github.com/UKPLab/sentence-transformers\n",
    "\n",
    "# UNIVERSAL SENTENCE ENCODER\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow_hub\n",
    "\n",
    "# FASTTEXT\n",
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import TfidfModel, fasttext_vectorizer, laser_embeddings, bert_embeddings, use_embeddings, cosine_similarity\n",
    "\n",
    "from arrays import same, different, synonyms, homonyms, sports_search, politics_search, food_search, science_search, finance_search, search_sentences, categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choose which model to use\n",
    "\n",
    "Available models:\n",
    "* tfidf_vectorizer\n",
    "* fasttext_vectorizer\n",
    "* laser_embeddings\n",
    "* bert_embeddings\n",
    "* use_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model to use:\n",
    "# tfidf_vectorizer, fasttext_vectorizer, laser_embeddings, bert_embeddings, use_embeddings\n",
    "model = TfidfModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "same_vectors = model.get_sentence_vec(same)\n",
    "different_vectors = model.get_sentence_vec(different)\n",
    "synonym_vectors = model.get_sentence_vec(synonyms)\n",
    "homonym_vectors = model.get_sentence_vec(homonyms)\n",
    "sports_vector = model.get_sentence_vec(sports_search)\n",
    "politics_vector = model.get_sentence_vec(politics_search)\n",
    "food_vector = model.get_sentence_vec(food_search)\n",
    "science_vector = model.get_sentence_vec(science_search)\n",
    "finance_vector = model.get_sentence_vec(finance_search)\n",
    "ss_vectors = model.get_sentence_vec(search_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'distance' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9d8592d4bd94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynonym_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynonym_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/nlp_notebooks/semantic_similarity/test_similarities/utils.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(first, second)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distance' is not defined"
     ]
    }
   ],
   "source": [
    "sim = cosine_similarity(synonym_vectors[0], synonym_vectors[1])\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "# Choose your search term\n",
    "search_term = science_vector\n",
    "\n",
    "for sentence in ss_vectors:\n",
    "    score = round(cosine_similarity(sentence, search_term),2)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.19 SCIENCE Scientists from 17 UK research centres are attempting to answer questions such as how long immunity lasts and why disease severity varies so much.\n\n0.11 SCIENCE Decoding goals and movement plans is hard when you don't understand the neural code in which those things are communicated.\n\n0.09 POLITICS This is election is a choice between President Trump’s strong stance with law and order and Joe Biden’s acquiescence to the anti-police left and siding with rioters.\n\n0.08 SPORTS And just like we saw in both games against FC Dallas, Nashville was sharp in the defensive third and in midfield.\n\n0.06 SPORTS The Vikings defense is already one of the best in the NFL and won’t ask much of Gladney.\n\n0.03 FOOD Made with fresh peaches, sugar, and a topping that bakes like slightly underbaked cookie dough, with crunchy sugar broiled on top.\n\n0.02 FOOD Is there anything better than a fresh batch of soft chocolate chip cookies?\n\n0.01 FINANCE Wednesday’s gains put the S&P 500 up more than 58% since hitting an intraday low on March 23.\n\n0.01 FINANCE Dow futures up 200 points in overnight trading after the index briefly erases 2020 losses\n\n0.0 POLITICS Democrats are willing to resume negotiations once Republicans start to take this process seriously.\n\n"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for (score,sentence,category) in zip(scores, search_sentences,categories):\n",
    "    results.append([score, sentence, category])\n",
    "\n",
    "results.sort(reverse=True)\n",
    "\n",
    "for row in results:\n",
    "    print(row[0], row[2], row[1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}