{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing fastText for semantic similarity\n",
    "\n",
    "Install [fasttext](https://fasttext.cc/) if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get fastText ready to use\n",
    "\n",
    "We are using the normal English model.\n",
    "\n",
    "More info about the fastText [models](https://fasttext.cc/docs/en/crawl-vectors.html) for different languages.\n",
    "\n",
    "> We distribute pre-trained word vectors for 157 languages, trained on Common Crawl and Wikipedia using fastText. These models were trained using CBOW with position-weights, in dimension 300, with character n-grams of length 5, a window of size 5 and 10 negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example about the word \"learning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "[-3.1326819e-02  5.8432957e-03  3.5721278e-05  3.2791961e-02\n",
      " -9.6422508e-03 -5.0007503e-02  1.6288273e-02  3.5059921e-02\n",
      " -6.6784739e-02 -1.8172603e-03 -1.8895891e-02 -5.0050311e-02\n",
      "  5.2792020e-02  3.0742858e-02  1.2085622e-02 -1.8491376e-03\n",
      "  5.5508241e-02 -9.5799835e-03  3.2117605e-02  1.1655847e-02]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(0.7456761598587036, 'learing'),\n (0.6895476579666138, 'Learning'),\n (0.6878188848495483, 'learning.This'),\n (0.6796225309371948, 'learning.The'),\n (0.6753033399581909, 'learning.It'),\n (0.6706692576408386, 'learning.So'),\n (0.6673312187194824, 'learning.What'),\n (0.6648250222206116, 'learning.But'),\n (0.664309024810791, 'learning-'),\n (0.6633586883544922, 'learning.As')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ft.get_word_vector('learning').shape)\n",
    "print(ft.get_word_vector('learning')[:20])\n",
    "\n",
    "# Get the nearest words for \"learning\"\n",
    "ft.get_nearest_neighbors('learning') # may take some time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the sts-benchmark training data and remove bad lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.pandas.read_table(\n",
    "    'stsbenchmark/sts-train.csv',\n",
    "    error_bad_lines=False,\n",
    "    skip_blank_lines=True,\n",
    "    usecols=[4, 5, 6],\n",
    "    names=[\"score\", \"s1\", \"s2\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A quick look at the dataset we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>s1</th>\n      <th>s2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.00</td>\n      <td>A plane is taking off.</td>\n      <td>An air plane is taking off.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.80</td>\n      <td>A man is playing a large flute.</td>\n      <td>A man is playing a flute.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.80</td>\n      <td>A man is spreading shreded cheese on a pizza.</td>\n      <td>A man is spreading shredded cheese on an uncoo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.60</td>\n      <td>Three men are playing chess.</td>\n      <td>Two men are playing chess.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.25</td>\n      <td>A man is playing the cello.</td>\n      <td>A man seated is playing the cello.</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   score                                             s1  \\\n0   5.00                         A plane is taking off.   \n1   3.80                A man is playing a large flute.   \n2   3.80  A man is spreading shreded cheese on a pizza.   \n3   2.60                   Three men are playing chess.   \n4   4.25                    A man is playing the cello.   \n\n                                                  s2  \n0                        An air plane is taking off.  \n1                          A man is playing a flute.  \n2  A man is spreading shredded cheese on an uncoo...  \n3                         Two men are playing chess.  \n4                 A man seated is playing the cello.  "
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>s1</th>\n      <th>s2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5706</th>\n      <td>0.0</td>\n      <td>Severe Gales As Storm Clodagh Hits Britain</td>\n      <td>Merkel pledges NATO solidarity with Latvia</td>\n    </tr>\n    <tr>\n      <th>5707</th>\n      <td>0.0</td>\n      <td>Dozens of Egyptians hostages taken by Libyan t...</td>\n      <td>Egyptian boat crash death toll rises as more b...</td>\n    </tr>\n    <tr>\n      <th>5708</th>\n      <td>0.0</td>\n      <td>President heading to Bahrain</td>\n      <td>President Xi: China to continue help to fight ...</td>\n    </tr>\n    <tr>\n      <th>5709</th>\n      <td>0.0</td>\n      <td>China, India vow to further bilateral ties</td>\n      <td>China Scrambles to Reassure Jittery Stock Traders</td>\n    </tr>\n    <tr>\n      <th>5710</th>\n      <td>0.0</td>\n      <td>Putin spokesman: Doping charges appear unfounded</td>\n      <td>The Latest on Severe Weather: 1 Dead in Texas ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      score                                                 s1  \\\n5706    0.0         Severe Gales As Storm Clodagh Hits Britain   \n5707    0.0  Dozens of Egyptians hostages taken by Libyan t...   \n5708    0.0                       President heading to Bahrain   \n5709    0.0         China, India vow to further bilateral ties   \n5710    0.0   Putin spokesman: Doping charges appear unfounded   \n\n                                                     s2  \n5706         Merkel pledges NATO solidarity with Latvia  \n5707  Egyptian boat crash death toll rises as more b...  \n5708  President Xi: China to continue help to fight ...  \n5709  China Scrambles to Reassure Jittery Stock Traders  \n5710  The Latest on Severe Weather: 1 Dead in Texas ...  "
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing two sentence paires with fastText as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 = A plane is taking off.\n",
      "s2 = An air plane is taking off.\n",
      "\n",
      "\n",
      "s3 = A man is playing the piano.\n",
      "s4 = A woman is playing the violin.\n"
     ]
    }
   ],
   "source": [
    "s1 = train_df.loc[0][1]\n",
    "s2 = train_df.loc[0][2]\n",
    "s3 = train_df.loc[45][1]\n",
    "s4 = train_df.loc[45][2]\n",
    "\n",
    "print(f's1 = {s1}')\n",
    "print(f's2 = {s2}')\n",
    "print('\\n')\n",
    "print(f's3 = {s3}')\n",
    "print(f's4 = {s4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastText fails when there are a lot of same words in the sentence, but the sentences are semantically different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 vs s2 = 0.10187679529190063\n",
      "Human score = 5.0\n",
      "fastText score = 4.5\n",
      "s3 vs s4 = 0.03787785768508911\n",
      "Human score = 1.0\n",
      "fastText score = 4.8\n",
      "s1 vs s3 = 0.28191500902175903\n",
      "s1 vs s4 = 0.28155577182769775\n"
     ]
    }
   ],
   "source": [
    "s1_vec = ft.get_sentence_vector(s1)\n",
    "s2_vec = ft.get_sentence_vector(s2)\n",
    "s3_vec = ft.get_sentence_vector(s3)\n",
    "s4_vec = ft.get_sentence_vector(s4)\n",
    "\n",
    "print(f's1 vs s2 = {distance.cosine(s1_vec,s2_vec)}')\n",
    "print(f'Human score = {train_df.loc[0][0]}')\n",
    "print(f'fastText score = {round((1-distance.cosine(s1_vec,s2_vec))*5,1)}')\n",
    "\n",
    "print(f's3 vs s4 = {distance.cosine(s3_vec,s4_vec)}')\n",
    "print(f'Human score = {train_df.loc[45][0]}')\n",
    "print(f'fastText score = {round((1-distance.cosine(s3_vec,s4_vec))*5,1)}')\n",
    "\n",
    "print(f's1 vs s3 = {distance.cosine(s1_vec,s3_vec)}')\n",
    "print(f's1 vs s4 = {distance.cosine(s1_vec,s4_vec)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Getting the human scores and the fasttext scores and comparing them\n",
    "\n",
    "**https://ixa2.si.ehu.es/stswiki/index.php/STS_benchmark_reproducibility**\n",
    "\n",
    "> The averaged word embedding baselines compute a sentence embedding by averaging word embeddings and then using cosine to compute pairwise sentence similarity scores. \n",
    "\n",
    "> FastText: Since, to our knowledge, the tokenizer and preprocessing used for the pre-trained FastText embeddings is not publicly described. We use the following heuristics to preprocess and tokenize sentences for Fast-Text: numbers are converted into words, text is lowercased, and finally prefixed, suffixed and infixed punctuation is recursively removed from each token that does not match an entry in the modelâ€™s lexicon;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load the dev data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev_df = pd.pandas.read_table(\n",
    "    'stsbenchmark/sts-dev.csv',\n",
    "    error_bad_lines=False,\n",
    "    skip_blank_lines=True,\n",
    "    usecols=[4, 5, 6],\n",
    "    names=[\"score\", \"s1\", \"s2\"])\n",
    "\n",
    "# removes punctuation from sentences\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "# For some reason some of the sentences were \"float\" datatypes \n",
    "dev_df['s1'] = dev_df['s1'].astype(str)\n",
    "dev_df['s2'] = dev_df['s2'].astype(str)\n",
    "\n",
    "\n",
    "dev_df['s1'] = dev_df.apply(lambda row: tokenizer.tokenize(row['s1']), axis=1)\n",
    "dev_df['s1'] = dev_df.apply(lambda row: ' '.join(row['s1']).lower() , axis=1)\n",
    "\n",
    "dev_df['s2'] = dev_df.apply(lambda row: tokenizer.tokenize(row['s2']), axis=1)\n",
    "dev_df['s2'] = dev_df.apply(lambda row: ' '.join(row['s2']).lower() , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>s1</th>\n      <th>s2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.00</td>\n      <td>a man with a hard hat is dancing</td>\n      <td>a man wearing a hard hat is dancing</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.75</td>\n      <td>a young child is riding a horse</td>\n      <td>a child is riding a horse</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.00</td>\n      <td>a man is feeding a mouse to a snake</td>\n      <td>the man is feeding a mouse to the snake</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.40</td>\n      <td>a woman is playing the guitar</td>\n      <td>a man is playing guitar</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.75</td>\n      <td>a woman is playing the flute</td>\n      <td>a man is playing a flute</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   score                                   s1  \\\n0   5.00     a man with a hard hat is dancing   \n1   4.75      a young child is riding a horse   \n2   5.00  a man is feeding a mouse to a snake   \n3   2.40        a woman is playing the guitar   \n4   2.75         a woman is playing the flute   \n\n                                        s2  \n0      a man wearing a hard hat is dancing  \n1                a child is riding a horse  \n2  the man is feeding a mouse to the snake  \n3                  a man is playing guitar  \n4                 a man is playing a flute  "
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Get the scores and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_scores = dev_df['score'].tolist()\n",
    "\n",
    "score_human = []\n",
    "\n",
    "for row in dev_scores:\n",
    "    score = row/5\n",
    "    score_human.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_machine = []\n",
    "\n",
    "for row in dev_df.itertuples(index=False):\n",
    "    s1_vec = ft.get_sentence_vector(str(row[1]))\n",
    "    s2_vec = ft.get_sentence_vector(str(row[2]))\n",
    "    score = (1-distance.cosine(s1_vec,s2_vec))\n",
    "    score_machine.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Compare human and fastText scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsonr: 55.3\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "result, _ = pearsonr(score_machine, score_human)\n",
    "print('Pearsonr:', end=' ')\n",
    "print(\"%.1f\" % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Numbers and written numbers are expressed very differently in fasttext\n",
    "Converting numbers to written form could produce better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 and forty        =   0.4287061095237732\n",
      "41 and forty-one    =   0.534650593996048\n",
      "40 and 41           =   0.11887586116790771\n",
      "forty and forty-one =   0.18680739402770996\n"
     ]
    }
   ],
   "source": [
    "vec_1 = ft.get_word_vector('40')\n",
    "vec_2 = ft.get_word_vector('forty')\n",
    "vec_3 = ft.get_word_vector('41')\n",
    "vec_4 = ft.get_word_vector('forty-one')\n",
    "print(f'40 and forty        =   {distance.cosine(vec_1,vec_2)}')\n",
    "print(f'41 and forty-one    =   {distance.cosine(vec_3,vec_4)}')\n",
    "print(f'40 and 41           =   {distance.cosine(vec_1,vec_3)}')\n",
    "print(f'forty and forty-one =   {distance.cosine(vec_2,vec_4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}